\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper, margin=2.5cm]{geometry}
\usepackage[spanish]{babel}
\begin{document}
	\section{Resumen}
A pesar de todos los avances científicos actuales el funcionamiento de las redes neuronales aun es un tema no muy explorado, aun así se sabe que juegan un papel importante en el aprendizaje ya que este se entiende como la creaciones de conexiones entre neuronas o la modificación de conexiones ya existentes. Con esto claro se puede entender el porque es importante simular este tipo de comportamientos mediante la creación de neuronas artificiales y el aprendizaje que estas realicen.

Al igual que cualquier tecnología, las redes neuronales necesitan dos elementos para que se puedan desarrollar los cuales son un concepto y la implementación. El primero hace referencia a el hecho de tener una idea una forma de pensamiento sobre algún tema que antes no existía. Por otro lado, la implementación es necesaria para poder hacer realidad el concepto que ya existe de lo contrario la tecnología no podrá madurar.

La historia de las redes neuronales tuvo altibajos, su inicio esta presente al inicio del siglo veinte con trabajos en la física, psicología y neuropsicología que surgieron de científicos como Hermann von Helmhotz, Ernst Mach e Ivan Pavlov. En los años cuarenta fue cuando comenzó una visión más moderna de las redes neuronales que se base en que las redes neuronales pueden computar cualquier función aritmética o lógica concepto formulado por Warren McCulloch y Walter Pitts.

Por otro lado, la aplicación de las redes neuronales apareció en los cincuenta con la creación de el perceptron y las reglas de aprendizaje de parte de Frank Rosenblatt. Otro algoritmo de aprendizaje importante fue el Widrow-Hoff el cual se sigue usando hoy en día. 

Sin embargo, estos algoritmos son muy simples y no sirven para entrenar a redes más complejas. Esto y el hecho de que no existían computadoras muy poderosas genero la idea de que las redes neuronales habían llegado a su fin. Pocos aportes se realizaron durante este periodo como es el caso de redes neuronales que actuaban como memoria desarrolladas por Teuvo Kohonen y James Anderson y redes autoorganizables creadas por Stephen Grossberg.

En los años ochenta las redes neuronales volvieron a ser importantes, y se hicieron aportes como el uso de mecanismos estadísticos para explicar el comportamiento de una red recurrente para ser usada como memoria y el algoritmo para entrenar entrenar varias redes perceptron que fue descubierto de manera individual por diferentes investigadores.

Al mismo tiempo que surgían nuevos conceptos surgían nuevas implementaciones para las redes neuronales, entre las implementaciones más notables se encuentran:
\begin{itemize}
	\item Pilotos automáticos para aviones y autos
	\item Simulaciones de vuelo
	\item Control de inyección de combustible
	\item Reconocimiento Facial
	\item Identificación de partículas en tiempo real
	\item Reconocimiento de voz
	\item Traducción en tiempo real de un lenguaje hablado
\end{itemize}
\newpage
\section{Deep learning}
Aprendizaje profundo es una rama del machine learning basado en un grupo de algoritmos que intentan modelar niveles altos de abstracción en datos.
En una red profunda hay varias capas entre la entrada y la salida permitiendo a los algoritmos usar procesamiento en múltiples capas compuestas de múltiples lineales y no lineales transformaciones.

Una observación puede ser representada en muchas formas como en valores de vectores de intensidad por pixeles, regiones de una forma en particular entre otras por lo que algunas representaciones son mejores que otras al simplificar la tarea de aprendizaje.

Investigaciones en este campo tratan de hacer mejores representaciones y crear modelos de aprendizaje para aprender estas representaciones de grandes cantidades de datos no etiquetados. Algunas representaciones están basadas en interpretaciones de patrones de procesamiento de información y comunicación en sistemas nerviosos.

Este tipo de aprendizaje ha sido aplicado a campos como visión por computadora, reconocimiento de voz, procesamiento de lenguaje natural, reconocimiento de audio y bioinformatica.

Las principales características del aprendizaje profundo son:
\begin{itemize}
	\item Usa una cascada de varias capas de unidades de procesamiento no lineales para extracción de características y trasformación. Lo algoritmos pueden ser supervisados o no supervisados.
	\item Son basados en aprendizaje (no supervisado) de múltiples niveles de característico representaciones de datos.
	\item Son parte del campo mas amplio del machine learning respecto al aprendizaje de representaciones de datos.
	\item Aprenden múltiples niveles de representaciones que corresponden a diferentes niveles de abstracción
\end{itemize}

Algoritmos de aprendizaje profundo están basados en representaciones distribuidas. La variación del numero de capas y el tamaño de estas puede ser usado para proveer diferentes cantidades de abstracción.
\newpage
\section{Reinforcement learning}
El aprendizaje reforzado es un área de machine learning la cual esta inspirada en la psicología conductista, se basa en la forma en la que los agentes de software deberían actuar en un ambiente con el fin de maximizar alguna noción de recompensa acumulativa.

El aprendizaje reforzado es aplicado e disciplinas como teoría de juegos, teoría de control, investigación de operaciones, teoría de la información, sistemas de multiagentes, estadística entre otras.

Este tipo de aprendizaje difiere del aprendizaje supervisado clásico en que las entradas/salidas no son presentadas y las acciones optimas no son explícitamente corregidas. Ademas existe un enfoque en rendimiento en linea, que involucra encontrar un balance entre exploración de territorio inexplorado y explotación del conocimiento actual.

El modelo básico de este aprendizaje es el siguiente:
\begin{itemize}
	\item Un grupo de estados agentes y ambientes \emph{S}.
	\item Un grupo de acciones \emph{A} de el agente.
	\item Políticas de transición de estados a acciones.
	\item Reglas que determinen la recompensa escalar inmediata de una transición, estas suelen ser estocásticas
	\item Reglas que describan lo que el agente observa.
\end{itemize}

El agente interactua con su ambiente tiempos discretos. En cada tiempo \emph{t} el agente recibe una observación \emph{$o_{t}$} que generalmente incluye una recompensa \emph{$r_{t}$}. Después, escoge una acción \emph{$a_{t}$} que es enviada a el ambiente. El ambiente se mueve a un nuevo estado \emph{$s_{t+1}$} y la recompensa \emph{$r_{t+1}$} asociada con la transición \emph{$(s_{t}, a_{t}, s_{t+1})$} es determinada.

El objetivo del agente de aprendizaje reforzado es colectar tantas recompensas como sea posible. El agente puede escoger cualquier acción como una función de la historia y puede hacer una elección de acción aleatoria.

El aprendizaje reforzado es útil para problemas que incluyen control robotico, programación de ascensores, telecomunicaciones, backgammon, checkers y go.

Los principales componentes detrás de su poder son el uso de muestras para optimizar el rendimiento y el uso de una aproximación de función para tratar ambientes grandes. Lo que permite ser usado en las siguientes situaciones.
\begin{itemize}
	\item Un modelo del ambiente es conocido pero una solución analítica no está disponible.
	\item Solo se da una simulación modelo del ambiente.
	\item La única forma de obtener información sobre el ambiente es interactuando con el.
\end{itemize}
\end{document}